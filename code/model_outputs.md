# Model Performance Summary

## **Inference Accuracy**
| Model          | Accuracy |
|---------------|----------|
| **AlexNet**   | 17.81%   |
| **ResNet18**  | 52.89%   |
| **EfficientNet** | 17.78% |
| **VGG16**     | 17.46%   |
| **InceptionV3**  |  28.32% |

---

## **Model Performance with Imbalanced Dataset**

| Model          | Train Accuracy | Validation Accuracy| Test Accuracy |
|---------------|----------|----------|------------|
| **AlexNet**   | 52.89%   | 52.75% | 52.99% |
| **ResNet18**  | 62.17%   | 43.04% | 42.16% |
| **EfficientNetb3** | 83.28% | 59.87% | 58.80% |  
| **VGG16**     |  52.89%  | 52.75% | 52.99% | 
| **InceptionV3** |  51.78%  | 47.25% | 47.98% | 

---

## **Training Details (ResNet50 - With UnderSampling)**
| Epoch | Train Loss | Train Accuracy | Val Loss | Val Accuracy |
|-------|-----------|---------------|----------|-------------|
| 1     | 1.1471    | 37.28%        | 1.1009   | 30.69%      |
| 2     | 1.0833    | 41.61%        | 1.5384   | 23.42%      |
| 3     | 1.0646    | 42.15%        | 1.3209   | 51.05%      |
| 4     | 1.0321    | 45.55%        | 1.1372   | 37.00%      |
| 5     | 1.0025    | 48.11%        | 2.7209   | 26.33%      |
| 6     | 0.9821    | 50.35%        | 1.5455   | 29.89%      |
| 7     | 0.9565    | 53.91%        | 1.1063   | 40.39%      |
| 8     | 0.9325    | 53.75%        | 1.6276   | 20.36%      |
| 9     | 0.8946    | 57.00%        | 1.8916   | 27.14%      |
| 10    | 0.8385    | 61.87%        | 1.6393   | 32.96%      |

---

## **Observations**
1. **AlexNet, EfficientNet, and VGG16 showed poor inference accuracy (~17-18%)**, indicating they struggle with the dataset.
2. **ResNet18 achieved the highest inference accuracy (52.89%)**, suggesting it is better suited for the task.
3. **VGG16 had better test accuracy (52.99%)** compared to ResNet18 (42.16%), despite poor inference accuracy.
4. **ResNet50 training showed improvement in accuracy over epochs, but validation accuracy fluctuated** and dropped in later epochs.
5. **Overfitting might be an issue in ResNet50**, as validation loss and accuracy do not consistently improve.

---

## **Next Steps**
- Investigate **dataset balancing strategies** further.
- Consider **data augmentation** to improve generalization.
- Experiment with **learning rate schedules** to stabilize training.
- **Fine-tune pre-trained models** on the dataset instead of training from scratch.

---

### **Conclusion**
ResNet18 and VGG16 seem to perform best, but dataset imbalance and overfitting need further investigation to improve generalization.

## **Training Details (Augmentation)**

### ResNet50
| **Epoch** | **Train Loss** | **Train Accuracy** | **Val Loss** | **Val Accuracy** |
|-----------|----------------|--------------------|--------------|------------------|
| 1         | 1.0394         | 48.42%             | 0.9872       | 53.31%           |
| 2         | 0.9890         | 52.06%             | 1.1293       | 49.27%           |
| 3         | 0.9812         | 52.71%             | 1.1625       | 32.15%           |
| 4         | 0.9790         | 52.55%             | 1.0030       | 52.83%           |
| 5         | 0.9765         | 51.82%             | 0.9682       | 52.83%           |
| 6         | 0.9513         | 52.67%             | 1.0748       | 55.74%           |
| 7         | 0.9344         | 53.88%             | 0.9762       | 54.77%           |
| 8         | 0.9209         | 53.96%             | 0.9279       | 53.63%           |
| 9         | 0.8993         | 54.28%             | 1.0337       | 52.83%           |
| 10        | 0.9288         | 54.69%             | 0.9687       | 48.79%           |

### VGGNET
| **Epoch** | **Train Loss** | **Train Acc** | **Val Loss** | **Val Acc** |
|-----------|----------------|---------------|--------------|-------------|
| 1 | 0.9410 | 52.98% | 0.8962 | 55.40% |
| 2 | 0.8910 | 55.45% | 0.8714 | 54.58% |
| 3 | 0.8725 | 56.75% | 0.9189 | 52.34% |
| 4 | 0.8404 | 59.20% | 0.8180 | 60.39% |
| 5 | 0.8008 | 61.77% | 0.8276 | 59.16% |
| 6 | 0.7624 | 63.45% | 0.7817 | 63.75% |
| 7 | 0.7191 | 65.72% | 0.8170 | 59.06% |
| 8 | 0.6475 | 69.92% | 0.7638 | 63.95% |
| 9 | 0.6116 | 71.63% | 0.8337 | 63.54% |
| 10 | 0.5639 | 74.91% | 0.7409 | 67.01% |
| 11 | 0.5085 | 77.00% | 0.7395 | 67.31% |
| 12 | 0.4720 | 79.57% | 0.9960 | 63.85% |
| 13 | 0.4072 | 82.27% | 0.8588 | 65.58% |
| 14 | 0.3849 | 83.39% | 0.8150 | 66.29% |
| 15 | 0.2976 | 88.33% | 0.8209 | 66.90% |
| 16 | 0.1346 | 94.50% | 1.1635 | 72.30% |
| 17 | 0.0821 | 97.22% | 1.4679 | 67.72% |
| 18 | 0.0520 | 98.32% | 1.6459 | 70.47% |
| 19 | 0.0584 | 97.94% | 1.4108 | 71.59% |
| 20 | 0.0139 | 99.75% | 1.5022 | 72.91% |

### AlexNet

| **Epoch** | **Train Loss** | **Train Acc** | **Val Loss** | **Val Acc** |
|-------|------------|---------------|----------|-------------|
| 1     | 0.9176     | 52.80         | 0.8779   | 55.91       |
| 2     | 0.8892     | 55.27         | 0.8531   | 58.76       |
| 3     | 0.8621     | 58.53         | 0.8797   | 54.18       |
| 4     | 0.8498     | 59.07         | 0.8658   | 56.52       |
| 5     | 0.8198     | 60.60         | 0.8512   | 57.54       |
| 6     | 0.7916     | 62.86         | 0.8131   | 60.69       |
| 7     | 0.7816     | 62.94         | 0.8004   | 61.61       |
| 8     | 0.7544     | 64.85         | 0.8177   | 59.88       |
| 9     | 0.7262     | 65.77         | 0.8332   | 60.18       |
|10     | 0.7006     | 67.52         | 0.7672   | 63.03       |
|11     | 0.6783     | 68.57         | 0.8454   | 61.30       |
|12     | 0.6525     | 70.20         | 0.7980   | 63.75       |
|13     | 0.6349     | 70.17         | 0.7574   | 65.58       |
|14     | 0.6071     | 72.06         | 0.8153   | 63.85       |
|15     | 0.5893     | 72.59         | 0.8002   | 63.95       |
|16     | 0.5605     | 74.48         | 0.7986   | 64.97       |
|17     | 0.5408     |75 .22         |0 .7757   |67 .52       |
|18     |0 .4747     |78 .55         |0 .7856   |67 .92       |
|19     |0 .4408     |80 .39         |0 .7926   |67 .62       |
|20     |0 .4233     |81 .58         |0 .8465   |67 .72       |

### InceptionV3

| **Epoch** | **Train Loss** | **Train Acc** | **Val Loss** | **Val Acc** |
|-----------|----------------|---------------|--------------|-------------|
| 1         | 0.9404         | 50.56%        | 0.8617       | 53.46%      |
| 2         | 0.7628         | 63.53%        | 0.7531       | 64.46%      |
| 3         | 0.5696         | 75.42%        | 0.9917       | 56.82%      |
| 4         | 0.3828         | 84.97%        | 0.8790       | 65.38%      |
| 5         | 0.2223         | 91.77%        | 1.0013       | 67.41%      |
| 6         | 0.2108         | 91.82%        | 1.0472       | 70.16%      |
| 7         | 0.0973         | 96.71%        | 0.7970       | 72.20%      |
| 8         | 0.0465         | 98.75%        | 0.8708       | 72.81%      |
| 9         | 0.0407         | 98.90%        | 0.8477       | 73.32%      |
| 10        | 0.0375         | 98.96%        | 0.9018       | 73.12%      |
| 11        | 0.0276         | 99.36%        | 0.9819       | 73.73%      |
| 12        | 0.0181         | 99.62%        | 0.9024       | 73.83%      |
| 13        | 0.0156         | 99.59%        | 0.9328       | 73.32%      |
| 14        | 0.0172         | 99.69%        | 0.9245       | 73.63%      |
| 15        | 0.0129         | 99.75%        | 0.9181       | 73.93%      |
| 16        | 0.0096         | 99.80%        | 0.9078       | 74.13%      |
| 17        | 0.0109         | 99.80%        | 0.9130       | 73.83%      |
| 18        | 0.0092         | 99.87%        | 0.9078       | 74.85%      |
| 19        | 0.0068         | 100.00%       | 0.8995       | 75.05%      |
| 20        | 0.0134         | 99.72%        | 0.9121       | 73.52%      |

### **EfficientNet-B0** 

| **Epoch** | **Train Loss** | **Train Acc** | **Val Loss** | **Val Acc** |
|-------|------------|----------------|-----------------|---------------------|
| 1     | 1.0486     | 43.73%         | 0.9863          | 54.18%              |
| 2     | 0.9661     | 52.14%         | 0.9261          | 56.21%              |
| 3     | 0.9277     | 54.53%         | 0.8980          | 55.50%              |
| 4     | 0.9028     | 55.71%         | 0.8829          | 56.82%              |
| 5     | 0.8849     | 56.80%         | 0.8714          | 57.23%              |
| 6     | 0.8629     | 58.51%         | 0.8576          | 57.54%              |
| 7     | 0.8491     | 58.58%         | 0.8494          | 58.76%              |
| 8     | 0.8408     | 59.25%         | 0.8497          | 58.35%              |
| 9     | 0.8292     | 59.25%         | 0.8310          | 58.86%              |
|10     | 0.8142     | 60.19%         | 0.8303          | 58.96%              |
|11     | 0.8045     | 61.56%         | 0.8163          | 59.78%              |
|12     | 0.7925     | 62.53%         | 0.8126          | 60.39%              |
|13     | 0.7835     | 62.91%         | 0.8067          | 61.51%              |
|14     | 0.7711     | 63.14%         | 0.8081          | 61.81%              |
|15     | 0.7596     | 64.37%         | 0.7984          | 61.20%              |
|16     | 0.7432     | 64.60%         | 0.7919          | 61.91%*      |
|17     | 0.7280     | 65.89%     | 0.7967          |62.42%               |
|18     | 0.7178   |67.22%           |0.7775        |62.73%               |
|19     |0.7100      |67.58%           |0 .7698           |63 .54%        |
|20    |0 .7023|67 .14%        |0 .7755|62 .93%            |

### EfficientNet-B3 Learning Rate = 0.0001

| **Epoch** | **Train Loss** | **Train Acc** | **Val Loss** | **Val Acc** |
|-----------|----------------|---------------|--------------|-------------|
| 1         | 1.0827         | 39.15%        | 1.0540       | 47.05%      |
| 2         | 1.0427         | 47.71%        | 1.0120       | 52.14%      |
| 3         | 1.0072         | 51.02%        | 0.9648       | 54.07%      |
| 4         | 0.9780         | 53.23%        | 0.9391       | 55.50%      |
| 5         | 0.9566         | 53.52%        | 0.9230       | 56.62%      |
| 6         | 0.9360         | 54.10%        | 0.9015       | 56.52%      |
| 7         | 0.9297         | 52.80%        | 0.8883       | 56.92%      |
| 8         | 0.9189         | 54.84%        | 0.8755       | 56.92%      |
| 9         | 0.9063         | 55.30%        | 0.8665       | 56.92%      |
| 10        | 0.8974         | 55.86%        | 0.8681       | 56.72%      |

## ResNet18 LR=0.001

| **Epoch** | **Train Loss** | **Train Acc** | **Val Loss** | **Val Acc** |
|-----------|----------------|---------------|--------------|-------------|
| 1/10      | 0.9575         | 51.76%        | 0.8280       | 58.96%      |
| 2/10      | 0.8184         | 61.49%        | 0.9104       | 60.49%      |
| 3/10      | 0.6470         | 70.76%        | 0.7862       | 63.34%      |
| 4/10      | 0.4524         | 81.18%        | 0.9618       | 65.99%      |
| 5/10      | 0.3373         | 86.81%        | 1.1559       | 59.88%      |
| 6/10      | 0.2054         | 92.54%        | 1.1585       | 65.38%      |
| 7/10      | 0.1975         | 92.36%        | 1.0456       | 68.64%      |
| 8/10      | 0.0723         | 97.86%        | 0.9950       | 69.96%      |
| 9/10      | 0.0303         | 99.24%        | 1.0609       | 69.96%      |
| 10/10     | 0.0214         | 99.59%        | 1.0446       | 71.79%      |

## Model Performance for augmented-images-v3

| Model         | Training Accuracy | Validation Accuracy | Epochs | Learning Rate |
|---------------|-------------------|---------------------|--------|---------------|
| InceptionV3   | 99.28%            | 71.43%              | 15     | 0.001         |
| InceptionV3   | 92.18%            | 56.78%              | 15     | 0.0001        |
| EffcientNetB3 | 79.65%            | 59.86%              | 10     | 0.001         |


